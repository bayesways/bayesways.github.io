<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>How to get started with LLM App building and Langchain? Part 2 of n | Konstantinos Vamvourellis</title> <meta name="author" content="Konstantinos Vamvourellis"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://bayesways.github.io/blog/2023/LLM-apps-p2/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Konstantinos </span>Vamvourellis</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">How to get started with LLM App building and Langchain? Part 2 of n</h1> <p class="post-meta">May 16, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/llm"> <i class="fas fa-hashtag fa-sm"></i> llm</a>   </p> </header> <article class="post-content"> <h1 id="overview">Overview</h1> <p>In <a href="https://bayesways.github.io/blog/2023/How-to-get-started-with-LLM-App-building-and-Langchain-Part-1-of-n/">Part 1 of n</a> we got a general overview of the Langchain framework for building LLM apps. We are now going deeper into some of the issues we will face as we start building our app. As a reminder, our goal is to build an app that can answer questions on a personal library of information, and provide citations for its answers. The fancy term for this is <em>retrieval augmented generation</em>. The high level structure of a chain appropriate for this task is described in <a href="https://docs.langchain.com/docs/use-cases/qa-docs" rel="external nofollow noopener" target="_blank">this</a> use case from the Langchain documentation. I am copying it here directly from the docs:</p> <p><strong>Ingestion</strong> In order use a language model to interact with your data, you first have to get in a suitable format. That format would be an <code class="language-plaintext highlighter-rouge">Index</code>. By putting data into an Index, you make it easy for any downstream steps to interact with it.</p> <p>There are several types of indexes, but by far the most common one is a Vectorstore. Ingesting documents into a vectorstore can be done with the following steps:</p> <ol> <li>Load documents (using a Document Loader)</li> <li>Split documents (using a Text Splitter)</li> <li>Create embeddings for documents (using a Text Embedding Model)</li> <li>Store documents and embeddings in a vectorstore</li> </ol> <p><strong>Generation</strong> Now that we have an Index, how do we use this to do generation? This can be broken into the following steps:</p> <ol> <li>Receive user question</li> <li>Lookup documents in the index relevant to the question</li> <li>Construct a PromptValue from the question and any relevant documents (using a PromptTemplate).</li> <li>Pass the PromptValue to a model</li> <li>Get back the result and return to the user.</li> </ol> <h1 id="implementation">Implementation</h1> <p>We will use python so let’s go to the documentation <a href="https://python.langchain.com/en/latest/use_cases/question_answering.html" rel="external nofollow noopener" target="_blank">page</a> for this use case from Langchain. This doc provides a quick start where the <em>ingestion</em> and <em>generation</em> parts are all combined together. Later on we will break it down to understand the components one by one. But first let’s see the big picture.</p> <p>Note that the document we use here is the State of the Union Address, so we need to first create a txt file containing the text in question and save in <code class="language-plaintext highlighter-rouge">../docs/state_of_the_union.txt</code> - copy past from <a href="https://www.whitehouse.gov/state-of-the-union-2023/" rel="external nofollow noopener" target="_blank">here</a>. The firefox read mode comes handy to give us the pure text without the extra stuff on the page. If you want a clean version to play with you can find an older state of the union address text file <a href="https://github.com/hwchase17/langchain/blob/master/docs/modules/state_of_the_union.txt" rel="external nofollow noopener" target="_blank">here</a>. If you use the latter, modify your query below to ask a question relevant to that text.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td> <td class="rouge-code"><pre><span class="c1"># requires: pip install openai langchain chromadb 
</span><span class="kn">import</span> <span class="n">os</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">OPENAI_API_KEY</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">your_api_key</span><span class="o">&gt;</span>

<span class="kn">from</span> <span class="n">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">TextLoader</span>
<span class="n">loader</span> <span class="o">=</span> <span class="nc">TextLoader</span><span class="p">(</span><span class="sh">'</span><span class="s">../docs/state_of_the_union.txt</span><span class="sh">'</span><span class="p">)</span>
  
<span class="kn">from</span> <span class="n">langchain.indexes</span> <span class="kn">import</span> <span class="n">VectorstoreIndexCreator</span>
<span class="n">qa_index</span> <span class="o">=</span> <span class="nc">VectorstoreIndexCreator</span><span class="p">().</span><span class="nf">from_loaders</span><span class="p">([</span><span class="n">loader</span><span class="p">])</span>
</pre></td> </tr></tbody></table></code></pre></div></div> <p>We will ask a question about a topic from the text. The president said the following (quoting from the text):</p> <blockquote> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> <td class="rouge-code"><pre>For example, I — I should have known this, but I didn’t until two years ago: Thirty million workers have to sign non-compete agreements for the jobs they take. Thirty million. So a cashier at a burger place can’t walk across town and take the same job at another burger place and make a few bucks more.
</pre></td> </tr></tbody></table></code></pre></div> </div> </blockquote> <p>Let’s ask the bot a question about it.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td> <td class="rouge-code"><pre><span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What did the president say about non-compete agreements?</span><span class="sh">"</span>
<span class="n">qa_index</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</pre></td> </tr></tbody></table></code></pre></div></div> <p>The response:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> <td class="rouge-code"><pre>" The president said that they have banned non-compete agreements so companies have to compete for workers and pay them what they're worth."
</pre></td> </tr></tbody></table></code></pre></div></div> <p>A pretty reasonable response.</p> <p>Let’s see what’s going on under the hood - have been waiting to say this.</p> <h1 id="implementation-break-down">Implementation break down</h1> <h3 id="ingestion">Ingestion</h3> <p>We first address the <strong>ingestion</strong> part of the steps. This means preparing the structure around the documents that we want to use when a user asks a question. The outcome of this part is a vector database, that we can pass to a chain during the <strong>generation</strong> part.</p> <h4 id="vectorindex">VectorIndex</h4> <p>The key functionality we need to understand is the <code class="language-plaintext highlighter-rouge">VectorstoreIndexCreator</code>, and specifically the following command.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> <td class="rouge-code"><pre><span class="nc">VectorstoreIndexCreator</span><span class="p">().</span><span class="nf">from_loaders</span><span class="p">([</span><span class="n">loader</span><span class="p">])</span>
</pre></td> </tr></tbody></table></code></pre></div></div> <p>What this does is the following:</p> <ol> <li>split the text in chunks (we will discuss the specifics but it doesn’t matter to much</li> <li>specify the LLM model which we will use to compute the embeddings (vector values assigned to each chunk)</li> <li>create a database where we store the vectors, we will use <code class="language-plaintext highlighter-rouge">Chroma</code> </li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td> <td class="rouge-code"><pre><span class="c1"># 1
</span><span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
<span class="kn">from</span> <span class="n">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="nc">CharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">texts</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="nf">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

<span class="c1"># 2
</span><span class="kn">from</span> <span class="n">langchain.embeddings</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="nc">OpenAIEmbeddings</span><span class="p">()</span>

<span class="c1"># 3
</span><span class="kn">from</span> <span class="n">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">.</span><span class="nf">from_documents</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
<span class="n">retriever</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">()</span>
</pre></td> </tr></tbody></table></code></pre></div></div> <p>If we want to preview the <strong>generation</strong> part we can add a fourth step</p> <ol> <li>create a chain that uses the vectors to answer questions</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td> <td class="rouge-code"><pre><span class="c1"># 4
</span><span class="n">qa_index</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="p">.</span><span class="nf">from_chain_type</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="nc">OpenAI</span><span class="p">(),</span> <span class="n">chain_type</span><span class="o">=</span><span class="sh">"</span><span class="s">stuff</span><span class="sh">"</span><span class="p">,</span> <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">)</span>

<span class="n">qa_index</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">query</span><span class="p">)</span> <span class="c1">#same query as before
</span></pre></td> </tr></tbody></table></code></pre></div></div> <h2 id="generation">Generation</h2> <p>Once we have our vector database we can use it for various tasks, aka create different kinds of chains.</p> <h4 id="retrieve-relevant-documents">Retrieve relevant documents</h4> <p>The simplest thing we can do is to retrieve a list of relevant documents to a specific query. The following code will return 4 documents, i.e. text chunks, ordered by relevance to the query we made.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td> <td class="rouge-code"><pre><span class="n">docsearch</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">()</span>
<span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What did the president say about non-compete agreements?</span><span class="sh">"</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">docsearch</span><span class="p">.</span><span class="nf">get_relevant_documents</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</pre></td> </tr></tbody></table></code></pre></div></div> <h4 id="ask-questions-based-on-the-documents">Ask questions based on the documents</h4> <p>Once we have our docs, we can ask questions on them with a simple LLM chain, which is made easy using the <code class="language-plaintext highlighter-rouge">load_qa_chain</code> template.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td> <td class="rouge-code"><pre><span class="kn">from</span> <span class="n">langchain.chains.question_answering</span> <span class="kn">import</span> <span class="n">load_qa_chain</span>
<span class="kn">from</span> <span class="n">langchain.llms.openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">chain</span> <span class="o">=</span> <span class="nf">load_qa_chain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="nc">OpenAI</span><span class="p">(),</span> <span class="n">chain_type</span><span class="o">=</span><span class="sh">"</span><span class="s">stuff</span><span class="sh">"</span><span class="p">)</span>
<span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What did the president say about non-compete agreements?</span><span class="sh">"</span>
<span class="n">chain</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">input_documents</span><span class="o">=</span><span class="n">docs</span><span class="p">,</span> <span class="n">question</span><span class="o">=</span><span class="n">query</span><span class="p">)</span>
</pre></td> </tr></tbody></table></code></pre></div></div> <p>From here on we can use the docs we retrieved as we like and combine it with other chains. The most common use case is passing the docs as part of the prompt input, called <em>context</em>, and asking the bot to answer using this context. See more examples <a href="https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html" rel="external nofollow noopener" target="_blank">here</a></p> <h2 id="references">References</h2> <ul> <li>Langchain <a href="https://python.langchain.com/en/latest/use_cases/question_answering.html" rel="external nofollow noopener" target="_blank">overview</a> of question and answering with sources</li> <li>Langchain <a href="https://python.langchain.com/en/latest/modules/indexes/getting_started.html" rel="external nofollow noopener" target="_blank">docs</a> for Indexes.</li> <li>Examples of</li> </ul> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"bayesways/bayesways.github.io","data-repo-id":"R_kgDOJEHZog","data-category":"Announcements","data-category-id":"DIC_kwDOJEHZos4CUlC1","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Konstantinos Vamvourellis. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>