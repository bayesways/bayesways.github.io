<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>How to get started with LLM App building and Langchain? Part 1 of n | Konstantinos Vamvourellis</title> <meta name="author" content="Konstantinos Vamvourellis"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://bayesways.github.io/blog/2023/LLM-apps-p1/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Konstantinos </span>Vamvourellis</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">How to get started with LLM App building and Langchain? Part 1 of n</h1> <p class="post-meta">May 15, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/llm"> <i class="fas fa-hashtag fa-sm"></i> llm</a>   </p> </header> <article class="post-content"> <p>I will use this space to document my effort to build LLM applications, starting pretty much from scratch. In order to have a concrete goal, I will aim to understand how to build an app that can answer questions and provide citations, utilizing a personal library of information. However, the lessons will apply equally to other use cases, some of which are listed in the references.</p> <h2 id="background">Background</h2> <p>It goes without saying that any LLM application is going to be based on <strong>Langchain</strong>. The <a href="https://docs.langchain.com/docs/" rel="external nofollow noopener" target="_blank">conceptual guide</a> is a good place to start.</p> <p>LLMs are game changing, partly because, they can simulate semantic understanding. This means that they can perform tasks that would typically require someone to understand the meaning of text, even if they don’t really “understand” the text. Text is an example of an unstructured data format, as opposed to a structured dataset such as a database for example. Querying a database is simple because the data is stored in a way that’s optimized for querying. Text on the other hand is words on a page without any pre-specified structure imposed on them. One can (correctly) object this point as human language is in fact at least partially structured, otherwise any random set of words would be meaningful. However for data retrieval purposes, a newspaper article is highly unstructured compared to a database. LLMs fill the gap and make retrieving information from unstructured text data possible, performing at the level we would expect someone with human language understanding to perform.</p> <p>The way LLM applications impose “structure” on text is via indexes (see the conceptual documentation <a href="https://docs.langchain.com/docs/components/indexing/" rel="external nofollow noopener" target="_blank">here</a>). These are emerging specialized data structures to facilitate LLM application building. Currently the main type of index used is a <em>vector databases</em> which stores <em>embeddings</em>, a numerical vector associated with a chunk of text.</p> <h2 id="basic-elements-of-langchain">Basic Elements of Langchain</h2> <h3 id="models">Models</h3> <p>Three kinds of models (quoting directly the documentation <a href="https://docs.langchain.com/docs/components/models/" rel="external nofollow noopener" target="_blank">page</a>)</p> <ul> <li>Large Language Models (LLMs) are the first type of models we cover. These models take a text string as input, and return a text string as output.</li> <li>Chat Models are the second type of models we cover. These models are usually backed by a language model, but their APIs are more structured. Specifically, these models take a list of Chat Messages as input, and return a Chat Message.</li> <li>Text Embedding Models. These models take text as input and return a list of floats.</li> </ul> <h3 id="inputoutput">Input/Output</h3> <p>Any LLM output can be post-processed to fit specific requirements. Langchain provides the specialized output parsers for this reason (see <a href="https://docs.langchain.com/docs/components/prompts/output-parser" rel="external nofollow noopener" target="_blank">here</a>)</p> <h3 id="indexes">Indexes</h3> <p>The database structure needed to facilitate LLM building. As we mentioned above, LLM applications building requires us to put some structure around text and store it, aka <em>index</em> text data. To do that Langchain provides specialized tools and integrates with the providers of such vector databases, such as <code class="language-plaintext highlighter-rouge">pinecone</code> and <code class="language-plaintext highlighter-rouge">chroma</code>. Note that to create a text embedding, typically we need to use a pre-trained LLM.</p> <h3 id="memory">Memory</h3> <p>Referes to the memory used by a chat agent. It’s important to distinguish between short and long memory. <em>Short memory</em> captures the context of a singular conversation with an agent, whereas <em>long memory</em> refers to the rest of information that persists between conversations. The main concrete example of memory usage is for storing the context of a conversation between a user and a chatbot, and expanding that context as the conversation evolves. Langchain provides tools to handle this scenario.</p> <h3 id="chains">Chains</h3> <p>Chain is the name given to an object that captures smaller components pieced together. The main type of a chain is an <strong>LLM-Chain</strong> which typically contains three components:</p> <ul> <li>an LLM model (such as <a href="https://platform.openai.com/docs/models/gpt-3" rel="external nofollow noopener" target="_blank">GPT3</a> or <a href="https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html" rel="external nofollow noopener" target="_blank">Flan</a>)</li> <li>a prompting template</li> <li>an output parser Each component might be broken down into further specialized pieces to achieve the desired goal of the application.</li> </ul> <p>The other common type of chain is an <strong>Index-related chain</strong> which uses the power of an LLM to interact with a specific text that the user chooses. The simplest way to pass the text to the LLM is to “stuff” it in the prompt of an LLM-Chain, hence defaulting back to the framework described above. However, that’s not always the best choice and Langchain provides some additional methods for interacting with (indexed) text using LLMs.</p> <h3 id="prompting">Prompting</h3> <p>Prompting refers to the text input given to an LLM or chat agent. Although it might sound simple, it is a vital piece of LLM app building. Langchain provides some frameworks for selecting the “right” prompt depending on the use case. The general task of prompting is more general, so we will have to come back to this.</p> <h3 id="agents">Agents</h3> <p>This refers to chains that do not have a pre-determined order of components. Instead, these chains consists of an “agent” and a pre-determined list of tools. The user interacts with the “agent” which has access to a suite of tools, and it’s up to the “agent” to decide what tool to use when, depending on the user input. We will leave this for a next post.</p> <h2 id="references">References</h2> <ul> <li><a href="https://docs.langchain.com/docs/" rel="external nofollow noopener" target="_blank">Conceptual guide to langchain</a></li> <li><a href="https://docs.langchain.com/docs/category/use-cases" rel="external nofollow noopener" target="_blank">List of LLM use cases</a></li> </ul> </article><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"bayesways/bayesways.github.io","data-repo-id":"R_kgDOJEHZog","data-category":"Announcements","data-category-id":"DIC_kwDOJEHZos4CUlC1","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Konstantinos Vamvourellis. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>